# Kapitola 4: Geocentrické modely

> Chapter 4: Geocentric models

```{r }
library(ggplot2)
library(latex2exp)
library(patchwork)
library(tibble)
library(gt)
library(splines)
library(dplyr)
library(rethinking)
```

## Lehké úkoly

### 4E1

$y_i \sim \text{Normal}(\mu, \sigma)$ - Věrohodnost dat

$\mu \sim \text{Normal}(0, 10)$ - Apriorní rozdělení

$\sigma \sim E(1)$ - Apriorní rozdělení

### 4E2

Jsou tam pouze dva parametry, $\mu$ a $\sigma$.

### 4E3

Čitatel (pokud předpokládáme nezávislost $\mu$, $\sigma$:

$$
P(\mu, \sigma, y) =
P(y | \mu, \sigma)P(\mu, \sigma) = 
P(y | \mu, \sigma)P(\mu)P(\sigma)
$$

Bayesův vzorec:

$$
P(\mu,\sigma|y) = \frac{
  P(y | \mu, \sigma)P(\mu)P(\sigma)
}{
  \int\int P(y | \mu, \sigma)P(\mu)P(\sigma) d\sigma d\mu
} = \frac{
  N(y|\mu, \sigma)N(\mu|\mu=0,\sigma=10)\text{Exp}(\sigma|\lambda=1)
}{
  \int\int N(y|\mu, \sigma)N(\mu|\mu=0,\sigma=10)\text{Exp}(\sigma|\lambda=1) d\sigma d\mu
}
$$

### 4E4

$y_i \sim \text{Normal}(\mu, \sigma)$ - Věrohodnost

$\mu_i = \alpha + \beta x_i$ - Lineární model

$\alpha \sim \text{Normal}(0, 10)$ - Apriorní rozdělení

$\beta \sim \text{Normal}(0, 1)$ - Apriorní rozdělení

$\sigma \sim E(2)$ - Apriorní rozdělení

### 4E5

V posteriorním rozdělení jsou tři parametry, $\sigma$, $\alpha$ a 
$\beta$. Jelikož je $\mu$ definováno deterministicky ostatními parametry,
nejedná se o parametr. To je naznačené i použitím $=$ místo $\sim$.

## Průměrné úkoly

### 4M1

```{r }
set.seed(421)
n <- 3e4
mu <- rnorm(n, mean = 0, sd = 10)
sigma <- rexp(n, rate = 1)
y <- rnorm(n, mean = mu, sd = sigma)

g1 <- 
  ggplot() +
  geom_density(aes(x = mu)) +
  theme_bw() +
  labs(title = TeX(r"(Apriorní rozdělení pro parametr $\mu$)"),
       x = TeX(r"($\mu$)"), y = TeX(r"($P(\mu)$)"))

g2 <- 
  ggplot() +
  geom_density(aes(x = sigma)) +
  theme_bw() +
  labs(title = TeX(r"(Apriorní rozdělení pro parametr $\sigma$)"),
       x = TeX(r"($\sigma$)"), y = TeX(r"($P(\sigma)$)"))

g3 <- 
  ggplot() +
  geom_density(aes(x = y)) +
  theme_bw() +
  labs(title = TeX(r"(Apriorní rozdělení pro parametr $y$)"),
       x = TeX(r"($y$)"), y = TeX(r"($P(y)$)"))

g3 + g1 / g2
```

### 4M2

```{r }
m42 <- alist(
  # Likelihood
  y ~ dnorm(mean = mu, sd = sigma),
  # Prior
  mu ~ dnorm(mean = 0, sd = 10),
  sigma ~ dexp(rate = 1)
)
```

### 4M3

$y_i \sim \text{Normal}(\mu_i, \sigma)$ - Věrohodnost dat

$\mu_i = \alpha + \beta x_i$ - Lineární model

$\alpha \sim \text{Normal}(0, 10)$ - Apriorní rozdělení

$\beta \sim U(0, 1)$ - Apriorní rozdělení

$\sigma \sim E(1)$ - Apriorní rozdělení

### 4M4

Pro apriorní rozdělení jsou použity informace z [@Lukasova1930_Archy]. Data
jsou nejspíše už málo relevantní, ale na ukázku postačující. Modelové zadání
bude předpokládat chlapce měřené v prvních třech letech, tedy `11-12`, `12-13` a
`13-14`.

$y_i \sim \text{Normal}(\mu_i, \sigma)$ - Věrohodnost dat

:::{.callout-tip title="Odůvodnění"}
Výška je přirozený proces a lze si ho představit jako součet přírůstků od
narození. Proto je rozumné předpokládat, že bude normálně rozdělena.
:::

$\mu = \alpha + \beta (x - \min x)$ - Vycentrovaný lineární model

:::{.callout-tip title="Odůvodnění"}
Střední hodnota výšky ($\mu$) lze popsat lineárním vztahem mezi výškou ($y$) a
rokem ($x$) měření. Roky jsou vycentrované ($x - \min x$) tak, aby $\alpha$
představovala průměrnou výšku v prvním roce. Přírůstek s každým rokem je
popsán parametrem $\beta$. Ideální by zde nejspíš byly ordinální proměnné,
ale to ještě neumíme :).
:::

$\alpha \sim \text{Normal}(143, 10)$ - Apriorní rozdělení

:::{.callout-tip title="Odůvodnění"}
Parametr $\alpha$ popisuje průměrný věk v prvním roce měření. [@Lukasova1930_Archy]
zjistila, že průměrná výška chlapců je 143 se směrodatnou odchylkou 5 cm.
Aby bylo respektováno to, že data nejsou nejnovější, je nejistota zdvojnásobena
a je použito $\sigma = 10$.
:::

$\beta \sim \chi^2(5)$ - Apriorní rozdělení

:::{.callout-tip title="Odůvodnění"}
Z [@Lukasova1930_Archy] lze odhadnout, že v prvních třech letech byl přírůstek 
mezi roky zhruba 6 cm. Přírůstek nemůže být negativní (žáci o rok starší
nebudou měřit v průměru méně) a proto je zvoleno $\chi^2$ rozdělení s $5$ti
stupni volnosti, což pokrývá zjištěná data.
:::

$\sigma \sim E(0.5)$ - Apriorní rozdělení

:::{.callout-tip title="Odůvodnění"}
O nejistotě výšek jako takových není v ve výzkumu zmínka. Je rozumné ale 
předpokládat, že mezi dětmi bude vysoká variabilita, jelikož jsou ještě ve
vývinu. Proto je zvoleno rozdělení, které pokrývá velké množství hodnot.
:::

### 4M5

Jelikož je tato informace reflektovaná ve striktně pozitivním apriorním
rozdělení pro $\beta$, nic se nemění.

### 4M6

V případě zvoleného apriorního rozdělení pro $\sigma$ je 
$P(\sigma > 8) = 0.0183$ a nabízejí se tři možnosti:

1) Změnit parametr apriorního rozdělení tak, aby $P(\sigma > 8)$ byla velmi
nízká. V Případě exponenciálního rozdělení nebude nikdy přesně nulová, ale
může se stát zanedbatelnou.
2) Ponechat apriorní rozdělení takové a useknout ho tak, že
$P(\sigma|\sigma > 8) = 0$.
3) Zvolit jiné rozdělení, například $U(0, 8)$.

### 4M7

Vytvoření dat:

```{r }
data(Howell1, package = "rethinking")
d2 <- Howell1[Howell1$age >= 18, ]
```

Originální model:

```{r }
m4.3 <- alist(
  height ~ dnorm(mu, sigma),
  mu <- a + b*(weight - mean(weight)),
  a ~ dnorm(178, 20),
  b ~ dlnorm(0, 1),
  sigma ~ dunif(0, 50)
)

set.seed(4271)
m471 <- quap(
  flist = m4.3,
  data = d2
)
```

Model bez centrování:

```{r }
m4.3b <- alist(
  height ~ dnorm(mu, sigma),
  mu <- a + b*weight,
  a ~ dnorm(178, 20),
  b ~ dlnorm(0, 1),
  sigma ~ dunif(0, 50)
)

set.seed(4272)
m472 <- quap(
  flist = m4.3b,
  data = d2
)
```

Porovnání posteriorních rozdělení:

```{r }
set.seed(4711)
postA <- extract.samples(m471)
set.seed(4722)
postB <- extract.samples(m472)

plot_post <- function(x, parameter, center, type) {
  l <- list(
    "a" = c(105, 160),
    "b" = c(0.7, 1.1),
    "g" = c(4, 6)
  )
  
  ggplot() +
    geom_density(aes(x = x))  + 
    scale_x_continuous(limit = l[[type]]) +
    theme_bw() +
    labs(x = TeX(parameter),
         y = TeX(paste0("P(", parameter, ")", ifelse(center, " - center", "- orig"))))
}

(
  plot_post(postA$a, r"($\alpha$)", TRUE, "a") +
  plot_post(postA$b, r"($\beta$)", TRUE, "b") +
  plot_post(postA$sigma, r"($\sigma$)", TRUE, "g")
) /
(
  plot_post(postB$a, r"($\alpha$)", FALSE, "a") +
  plot_post(postB$b, r"($\beta$)", FALSE, "b") +
  plot_post(postB$sigma, r"($\sigma$)", FALSE, "g")
)
```

:::{.callout-tip title="Interpretace"}
Posteriorní rozdělení pro parametr $\beta$ je prakticky identické a mezi
modely se neliší. To dává smysl, vzhledem k tomu, že koeficient má stejnou
interpretaci v obou modelech.

Pro parametr $\alpha$ je interpretace odlišná. V modelech v prvním řádku
(vycentrovaná váha) parametr reprezentuje průměrnou výšku pro průměrnou váhu,
zatímco v druhém řádku (nevycentrovaná váha) reprezentuje průměrnou výšku pro
nulovou váhu (což prakticky nedává smysl).
:::

```{r }
#| fig.height: 1.6
#| fig.width: 5.5
#| fig.align: center
cov_mx <- function(x, h) {
  x |> 
    cov() |> 
    as_tibble(rownames = "var") |> 
    gt() |> 
    fmt_number(decimals = 4) |> 
    tab_header(h) |> 
    wrap_table()
}

cov_mx(postA, h = "Vycentrovaný model") +
  cov_mx(postB, h = "Nevycentrovaný model")
```

:::{.callout-tip title="Interpretace"}
Rozptyl parametrů $\beta$ a $\sigma$ je v obou modelech velmi podobný. 
Kovariance mezi $\beta$ a $\sigma$ je také prakticky identická. Co je ale 
výrazně horší pro nevycentrovaný model jsou vlastnosti parametru $\alpha$.
Ten má jak vyšší rozptyl, tak vyšší kovariance s oběma parametry. To také
může být důvodem, proč se zdá posteriorní rozdělení parametru $\sigma$
větší.
:::

### 4M8


```{r }
num_knots <- 20
dg <- 3

data(cherry_blossoms, package = "rethinking")
d3 <- cherry_blossoms[complete.cases(cherry_blossoms$doy), ]
knot_list <- quantile(d3$year, probs = seq(0, 1, length.out = num_knots + 2))
knot_list <- knot_list[-c(1, num_knots + 2)]
B <- bs(d3$year,
        knots = knot_list,
        degree = dg,
        intercept = FALSE)

set.seed(4271)
m47 <- quap(
  flist = alist(
    D ~ dnorm(mu, sigma),
    mu <- a + B %*% w,
    a ~ dnorm(100, 10),
    w ~ dnorm(0, 5),
    sigma ~ dexp(1)
  ),
  data = list(
    D = d3$doy,
    B = B
  ),
  start = list(
    w = rep(0, length = ncol(B))
  )
)

set.seed(88)
post <- link(m47)
pred <- apply(post, 2, mean)
pi <- apply(post, 2, PI)

plot(doy ~ year, data = d3, col = col.alpha("black", 0.4))
lines(d3$year, pred, col = "red", lwd = 3)
lines(d3$year, pi[1,], col = "blue", lwd = 2, lty = 2)
lines(d3$year, pi[2,], col = "blue", lwd = 2, lty = 2)
abline(v = knot_list, lty = 3, col = "darkred", lwd = 2)
title(paste0("Number of nots: ", num_knots,
             ", degrees:", dg, ", params: ", ncol(B)))
```

## Těžké úkoly

### 4H1

Normalizace dat a uložení hyperparametrů pro predikci.

```{r }
hp <- list(
  mean_h = mean(Howell1$height),
  mean_w = mean(Howell1$weight),
  sd_h   = sd(Howell1$height),
  sd_w   = sd(Howell1$weight)
)

h41d <- Howell1
h41d$H <- (h41d$height - hp$mean_h) / hp$sd_h
h41d$W <- (h41d$weight - hp$mean_w) / hp$sd_w
h41d <- h41d[order(h41d$W), ]
```

Graf váhy a výšky.

```{r }
plot(H ~ W, data = h41d)
```

Vypadá to, že by mohla být dobrý volba lineární spline regrese s knotem okolo 
-1.

```{r }
h41B <- bs(x = h41d$W, knots = -1, degree = 1)
h41m <- quap(
  flist = alist(
    H ~ dnorm(mu, sigma),
    mu <- a + B %*% w,
    a ~ dnorm(0, 10),
    w ~ dnorm(0, 10),
    sigma ~ dexp(1)
  ),
  data = list(
    H = h41d$H,
    B = h41B
  ),
  start = list(
    w = rep(0, length = ncol(h41B))
  )
)

set.seed(99)
post <- sim(h41m)
post <- apply(post, 2, \(x) x * hp$sd_h + hp$mean_h) # Normalizace
pred <- apply(post, 2, mean)
pi <- apply(post, 2, PI)

plot(height ~ weight, data = h41d, col = col.alpha("black", 0.4))
lines(h41d$weight, pred, col = "red", lwd = 1)
lines(h41d$weight, pi[1,], col = "blue", lwd = 2, lty = 2)
lines(h41d$weight, pi[2,], col = "blue", lwd = 2, lty = 2)
abline(v = -1 * hp$sd_w + hp$mean_w, lty = 3, col = "darkred", lwd = 2)
title("Regrese na čistých datech.")
```

Regrese na data sedí pěkně. Apriorní rozdělení jsou široká. Predikce nových 
hodnot na grafu:

```{r warning=FALSE}
# h41p <- tibble(
#   Individual = 1:5,
#   weight = c(46.95, 43.72, 64.78, 32.59, 54.63),
#   W = (weight - hp$mean_w ) / hp$sd_w
# )
# 
# set.seed(965)
# post2 <- sim(h41m, data = data.frame(B = predict(h41B, h41p$W)))
# post2 <- apply(post2, 2, \(x) x * hp$sd_h + hp$mean_h) # Normalizace
# pred2 <- apply(post2, 2, mean)
# pi2 <- apply(post2, 2, PI)
# 
# plot(height ~ weight, data = h41d, col = col.alpha("black", 0.4))
# points(h41p$weight, pred2, col = "darkgreen", lwd = 2, pch = 8)
# points(h41p$weight, pi2[1,], col = "darkblue", lwd = 2, lty = 2)
# points(h41p$weight, pi2[2,], col = "darkblue", lwd = 2, lty = 2)
# title("Predikce")
```

```{r }
# h41p |> 
#   select(-W) |> 
#   mutate(
#     Predikce = pred2,
#     "5.5 %"  = pi2[1, ],
#     "94.5 %" = pi2[2, ]
#   ) |> 
#   gt()
```

### 4H2

Filtrace dat.

```{r }
h42d <- filter(Howell1, age < 18)
nrow(h42d)
```

Lineární regrese `height ~ weight`.

```{r }
# Požadované parametry
h42mean <- 5
h42sd <- 10
# Konvertování parametrů
h42logmean <- log(h42mean^2 / sqrt(h42sd^2 + h42mean^2))
h42logsd <- sqrt(log(1 + (h42sd^2 / h42mean^2)))

h42m <- quap(
  flist = alist(
    height ~ dnorm(mu, sigma),
    mu <- alpha + beta * weight,
    alpha ~ dnorm(170, 20),
    beta ~ dlnorm(h42logmean, h42logsd),
    sigma ~ dexp(1)
  ),
  data = h42d
)

summary(h42m)
```

:::{.callout-tip title="interpretace"}
V průměru očekáváme, že s 10 kg navíc se zvýší výška o 27 cm.
:::

```{r }
set.seed(22)
pred <- sim(h42m)
h42predci <- apply(pred, 2, PI)
h42expected <- link(h42m)
h42muci <- apply(h42expected, 2, PI)

ggplot(h42d, aes(x = weight, y = height)) +
  geom_ribbon(aes(ymin = h42predci[1, ], ymax = h42predci[2, ]),
              fill = "lightblue") +
  geom_ribbon(aes(ymin = h42muci[1, ], ymax = h42muci[2, ]),
              fill = "darkblue") +
  geom_line(aes(y = h42mu), color = "blue", linewidth = 1) +
  geom_point() +
  theme_bw()
```

:::{.callout-tip title="interpretace"}
Model předpokládá lineární vztah, což ale neodpovídá datům. Model v nízkých a vysokých hodnotách nadhodnocuje zatímco v průměrných podhodnocuje. Bylo by 
vhodnější buď předzpracovat proměnnou `weight` a nebo změnit vztah ve funkce
a přidat polynomy.
:::

### 4H3

Úprava dat.

```{r }
h43d <- mutate(Howell1, lweight = log(weight))
dim(h43d)
```

Model.

```{r }
h43m <- quap(
  flist = alist(
    height ~ dnorm(mu, sigma),
    mu <- alpha + beta * lweight,
    alpha ~ dnorm(170, 20),
    beta ~ dnorm(50, 100),
    sigma ~ dexp(5)
  ),
  data = h43d
)

summary(h43m)
```

:::{.callout-tip title="interpretace"}
V průměru očekáváme, že s 10% nárůstem váhy se zvýší výška o
$46,82\ln(110/100)=4,46 cm$
:::

```{r }
set.seed(22)
h43pred <- sim(h43m)
h43predci <- apply(h43pred, 2, PI)
h43expected <- link(h43m)
h43mu <- colMeans(h43expected)
h43muci <- apply(h43expected, 2, PI)

ggplot(h43d, aes(x = weight, y = height)) +
  geom_ribbon(aes(ymin = h43predci[1, ], ymax = h43predci[2, ]),
              fill = "lightblue") +
  geom_ribbon(aes(ymin = h43muci[1, ], ymax = h43muci[2, ]),
              fill = "darkblue") +
  geom_line(aes(y = h43mu), color = "blue", linewidth = 1) +
  geom_point() +
  theme_bw()
```

:::{.callout-tip title="interpretace"}
Tenhle model je mnohem lepší a sedí jak na nezletilé, tak na dospělé
jedince.
:::

### 4H4

Data.

```{r }
h44d <- 
  Howell1 |> 
  mutate(
    weight_s = standardize(weight),
    weight_s2 = weight_s^2
  )
```

Model z kapitoly.

```{r }
h44m <- quap(
  flist = alist(
    height ~ dnorm(mu, sigma),
    mu <- a + b1 * weight_s + b2 * weight_s2,
    a ~ dnorm(178, 20),
    b1 ~ dlnorm(0, 1),
    b2 ~ dnorm(0, 1),
    sigma ~ dunif(0, 50)
  ),
  data = h44d
)
```

Apriorní model.

```{r }
set.seed(78)
h44p <- extract.prior(h44m)
h44s <- link(h44m, post = h44p)

ggplot(Howell1, aes(x = weight, y = height)) +
  geom_point()
  geom_point()
```


# Reference